<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <title></title>
    <link rel="stylesheet" href="src/style.css">
</head>
<body class='content-md night'>
<pre class="content-md">
<h1> Machine Learning</h1>
<h2> Numpy</h2>
import numpy as np
<pre class="code">
mylist = [1,2,3]

myarr = np.array(mylist)
</pre>
Создать массив от 0 до 100 с шагом 20
<pre class="code">
np.arange(0, 101, 20)
</pre>
Получить массив из равноудаленных чисел от 0 до 5 (21 число)
<pre class="code">
np.linspace(0, 5, 21)
</pre>
Получить список из 5-ти случайных целых чисел в двух строках (каждой) от 1 до 70
<pre class="code">
np.random.randint(1, 70, (2, 5))
</pre>
Получить список случайных зафиксированных чисел
<pre class="code">
np.random.seed(42)
np.random.rand(4)
</pre>
Создать одномерный массив и изменить его в двумерный с 5 строками и с 5 столбцами
<pre class="code">
arr = np.arange(0, 25)
arr.reshape(5,5)
</pre>
Найти максимальное и минимальное число
<pre class="code">
arr.max()
arr.min()
</pre>
Получить индекс максимального и минимального значения
<pre class="code">
arr.rangmax()
arr.rangmin()
</pre>
Посмотреть форму массива (кол-во столбцов и строк)
<pre class="code">
arr.shape
</pre>
Получить числа  из массива сначала до индекса 5 (последний не включается)
<pre class="code">
arr[:5]
</pre>
Присвоить элементам массива от 5 до последнего число 66
<pre class="code">
arr[5:] = 66
</pre>
Чтобы присвоить массив другой переменно, нужно использовать метод copy
Если просто присвоить то это присвоит ссылки и изменения в одном массиве, применяться к другому.
<pre class="code">
arr_copy = arr.copy()
</pre>

Получить массив чисел где число больше 4 из другого массива
<pre class="code">
arr2 = arr1[arr1>4]
</pre>

Сумма строк и сумма колонок
<pre class="code">
arr.sum(axis=0) #сумма колонок
arr.sum(axis=1￼) #сумма строк￼
</pre>
Создать массив из 10 нулей
<pre class="code">
np.zeros(10)
</pre>

Сделать абсолютные значения в массиве
<pre class="code">
np.abs(arr)
</pre>

<h2> Pandas</h2>
<pre class="code">
import pandas as pd
</pre>

Информация о таблице
<pre class="code">
df.info()
df.C().transpose()
</pre>
Перевернуть таблицу (поменять местами строки со столбцами)
<pre class="code">
df = df.T # или df.transpose()
</pre>
Создать именованный список
<pre class="code">
personal_data = pd.Series(data=[26,33], index=[‘Ivan’, ‘Maria’])
</pre>
Узнать ключи массива
<pre class="code">
personal_data.keys()
</pre>
Сложить два массива и отсутсвующие значения заменить 0
<pre class="code">
sales_1.add(sales_2, fill_value=0)
</pre>
Создание dataframe
<pre class="code">
df = pd.DataFrame(data=mydata, index=myindex, columns=columns_names)
df = pd.DataFrame({“age”:[25,35,45], “isMale”:[True, False, True]})
</pre>
Создание dataframe из csv файла
<pre class="code">
df=pd.read_csv('/home/bobmarley/UNZIP_ME_FOR_NOTEBOOKS_ML_RUS_V1/UNZIP_ME_FOR_NOTEBOOKS_ML_RUS_V1/03-Pandas/tips.csv')
</pre>
Узнать названия колонок и строк
<pre class="code">
df.columns
df.index
</pre>
Показать первые или последние десять строк dataframe
<pre class="code">
df.head(10)
df.tail(10)
</pre>
Получить общую статистику по dataframe
<pre class="code">
df.describe()
</pre>
Получить среднее значение в столбце
<pre class="code">
df[‘price’].mean()
</pre>

Вывести два столбца из df
<pre class="code">
df[[‘total_bill’,’tip’]]
</pre>

Удалить колонку price
<pre class="code">
df = df.drop(‘price’, axis=1)
</pre>

Установить колонку Payment_ID в качестве индекса строк (названия строк)
<pre class="code">
df.set_index(‘Payment_ID’)
</pre>

Отменить индекс
<pre class="code">
df = df.reset_index()
</pre>

Доступ к строке по номеру и индексу
<pre class="code">
df.iloc[0] или df.iloc[0:5]
df.loc[‘Marc’] или df.loc[[‘Marc’, ‘Jack’]]
</pre>

Добавить строку в dataframe
<pre class="code">
df = df.append(one_row)
</pre>

Отфильтровать строки по условию, где в столбце Pop значение больше 50
<pre class="code">
df[df[“Pop”] > 50]
</pre>

В условиях AND это &, а OR это |. Условия записываются в скобки
<pre class="code">
df[(df[“Pop”] > 50) & (df[“Sex”] == “Male”])]
</pre>

Полезный метод проверки есть ли одно из значений
<pre class="code">
df[df[‘Day’].isin([‘Saturday’, ‘Sunday’])]
</pre>

Применить функцию к значениям столбца
<pre class="code">
def someFunc(val):
	return f’Value = {val}’

df[“new_column”] = df[“some_column”].apply(someFunc)

</pre>
Применить функцию к нескольким столбцам
<pre class="code">
def quality(total_bill,tip):
    if tip/total_bill  > 0.25:
        return "Generous"
    else:
        return "Other"

df['Tip Quality'] = df[['total_bill','tip']].apply(lambda df: quality(df['total_bill'],df['tip']),axis=1)

</pre>
Или сделать это быстрее и проще
<pre class="code">
df['Tip Quality'] = np.vectorize(quality)(df['total_bill'], df['tip'])
</pre>

Передать несколько значений в функцию (помимо строки)
<pre class="code">
df['50%'] = df.apply(MyFunc, args=['50%', 100], axis=1)
</pre>

Сортировка по значениям (колонки)
<pre class="code">
df.sort_values(‘tip’)
df.sort_values(‘tip’, ascending=False) #обратная сортировка
df.sort_values([‘tip’,’size’], ascending=False)  #сортировка по двум колонкам (сначала tip, затем по size)
</pre>

Найти максимальное и минимальное значение
<pre class="code">
df[‘total_bill’].max()
df[‘total_bill’].idxmax() - получить index строки с максимальным значением
df[‘total_bill’].min()
df[‘total_bill’].idxmin() - получить index строки с миниимальным значением
</pre>
Найти корреляцию
<pre class="code">
df.corr()
df.corr().quality #отобразить корреляцию только относительно стобца quality
</pre>

Посчитать кол-во строк со значением (категоризация)
<pre class="code">
df[‘some_column’].value_counts()
df[‘some_column’].unique() # массив уникальных значений
df[‘some_column’].nunique() # кол-во уникальных значений
</pre>

Замена значений в колонке
<pre class="code">
df[‘some_column’].replace(‘Value’, ‘V’)
df[‘some_column’].replace([‘Value’, ‘Value2’], [‘V’, ‘V2’])

replace = {‘Value’:’V’, ‘Value2’:’V2’}
df[‘some_column’].map(replace)
</pre>

Отобразить дубликаты
<pre class="code">
df.duplicated()
df.drop_duplicates() #удалить дубликаты
</pre>

Взять диапазон
<pre class="code">
df[‘some_column’].between(10,20, inclusive=True) # с включение верхней границы значений (20)
</pre>

Отсортировать и показать первые 10 строк
<pre class="code">
df.nlargest(10,’tip’)
df.nsmallest(10,’tip’) # сортировка по наименьшему
</pre>

Получить 5 случайных строк из таблицы
<pre class="code">
df.sample(5)
df.sample(frac=0.1) # получить 10% строк из таблицы
</pre>

Сделать dummies переменные из категориальных значений
<pre class="code">
pd.get_dummies(df_new, drop_first=True) #drop_first - оставляет по минимуму колонок
</pre>

Цикл по датафрейму по строкам
<pre class="code">
for idx, row in df.iterrows():
        makeMoney(row)
</pre>



<h2> Отсутствующие данные в Pandas</h2>
Показать отсутсвующие значения
<pre class="code">
df.isnull()
df.notnull()
df[df['first_name'].notnull()]
</pre>

Удалить
<pre class="code">
df = df.dropna() #Удалить все строки где есть хотя бы одно неопределенное значение
df.dropna(tresh=1) #удалить строки с неопределенными значениями, но оставить те, где есть хотябы одно определенное значение
df.dropna(subset=[‘last_name’]) #удалить те строки, где неопределенные значения в стобце last_name
df.dropna(axis=1) #удалить столбцы, где есть хоть одно значение
df.drop('a', inplace=True, axis=1) # удалить столбец а
</pre>

Заменить
<pre class="code">
df.fillna(‘new value’) #заменить везде (очень редкий случай)
df[‘price’] = df[‘price’].fillna(0) #заменить на ноль в столбце price
</pre>

Группировка
<pre class="code">
df.groupby(‘year’).mean() #группировать по году, а остальные колонки усреднить
df.groupby([‘year’, ‘speed’]).mean() #группировать две колонки (мультииндекс)
</pre>

Достать строки из мультииндекса
<pre class="code">
df.xs(key=120, level=’speed’) #получить строки со значением 120 в столбце speed (обычно это применяется для второго индекса, так для первого достаточно loc
</pre>

Агрегация
<pre class="code">
df.agg({‘speed’: [‘max’, ‘mean’], weight: [‘mean’, ‘std’]})
</pre>

Обьединение датафреймов
<pre class="code">
pd.concat([df1, df2], axis=1) #обьеденить по столбцам (добавляются столбцы)
pd.concat([df1, df2], axis=0) #обьеденить по строкам (добавляются строки)
</pre>

Merge
<pre class="code">
pd.merge(table1, table2, how=’inner’, on=’email’) # inner оставит только совпадающие значения
pd.merge(table1, table2, how=”left”, on=”email”) # left оставить значения email из левой (table1) и дополнит столбцом из правой таблицы у которых такой же email. Тех email которых нет в левой таблице, не добавяться. how=”right” делает тоже самое, но наоборот)
pd.merge(table1, table2, how=”outer”, on=”email”) # outer оставит все значения email из двух таблиц и отсутсвующие значения в столбцах заполнит NaN
pd.merge(table1, table2, left_index=True,right_on=”email”, how=”inner”) #соединяет таблицы, левую по индексу, а правую по колонке email.
</pre>

Работа со строками
<pre class="code">
names = pd.Series(['andrew','bobo','claire','david','4'])
names.str.isdigit()
names.str.capitalize()
messy_names.str.replace(";","").str.strip().str.capitalize()
</pre>

<h2> Полезные Функции Pandas</h2>
Процентное изменение, от предыдущего значения к настоящему
<pre class="code">
df.change = df.price.pct_change()
</pre>

Преобразовать (конвертировать) значения в численный тип:
<pre class="code">
df[['price','qty','quoteQty']] = df[['price','qty','quoteQty']].astype(float)
</pre>

<pre class="code">
Matplotlib
import matplotlib.pyplot as plt
fig = plt.figure()
axes = fig.add_axes([0,0,1,1])
axex.plot(x,y)

plt.show()
</pre>

<h2> Seaborn</h2>
<pre class="code">
import seaborn as sns
</pre>

График bar plot
<pre class="code">
sns.countplot(data=df, x='target')
</pre>

График pairplot
<pre class="code">
sns.pairplot(df[['age','trestbps', 'chol','thalach','target']], hue='target')
</pre>

График histplot
<pre class="code">
sns.histplot(data=df,x='tenure',bins=60)
</pre>

График countplot
<pre class="code">
sns.countplot(x='type', hue='quality', data=df)
</pre>

Heatmap который показывает корреляцию между колонками
<pre class="code">
plt.figure(figsize=(12,8),dpi=200)
sns.heatmap(df.corr(), annot=True)
</pre>

Тепловая карта для кореляции
<pre class="code">
plt.figure(figsize=(8,6))
sns.heatmap(df.corr(),cmap='coolwarm')
</pre>

График кластер мап
<pre class="code">
sns.clustermap(df.corr(),cmap='viridis')
</pre>

Повернуть обозначения оси x на 90 градусов для лучшего отображения
<pre class="code">
plt.xticks(rotation=90);
</pre>

<h2> SKLearn</h2>
Разбиение данных на тестовый и обучающий набор
<pre class="code">
from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.1, random_state=101) #X - признаки, y - целевая переменная
</pre>

Масштабирование признаков
<pre class="code">
from sklearn.preprocessing import StandardScaler
scaler = StandardScaler()
scaler.fit(X_train)
X_train = scaler.transform(X_train)
X_test = scaler.transform(X_test)
</pre>

ElasticNet
<pre class="code">
from sklearn.linear_model import ElasticNet
elastic_model = ElasticNet()
</pre>

Или

<pre class="code">
from sklearn.linear_model import ElasticNetCV
elastic_model = ElasticNetCV(l1_ratio=[.1, .5, .7, .9, .95, .99, 1],
                          eps=0.001, n_alphas=100,max_iter=1000000)
</pre>

GridSearchCV
<pre class="code">
param_grid = {'alpha':[0.1, 1, 5, 50, 100],
             'l1_ratio':[.1, .5, .7, .95, .99, 1]}

from sklearn.model_selection import GridSearchCV
grid_model = GridSearchCV(estimator=elastic_model,
                         param_grid=param_grid,
                         scoring='neg_mean_squared_error',
                         cv=5,
                         verbose=2)
grid_model.fit(X_train,y_train)
grid_model.best_params_

y_pred = grid_model.predict(X_test)

from sklearn.metrics import mean_absolute_error, mean_squared_error
mean_absolute_error(y_test,y_pred)
np.sqrt(mean_squared_error(y_test,y_pred))
</pre>

Логистическая регрессия мультиклассовая

<pre class="code">
from sklearn.linear_model import LogisticRegressionCV
from sklearn.model_selection import GridSearchCV #поиск по сетке
clf = LogisticRegressionCV(max_iter=5000).fit(X_train, y_train)

clf.C_ #отобразить параметр С
log_model.get_params() #отобразить другие параметры
clf.coef_ #отобразить коефициенты модели
</pre>

Оценка работы модели
<pre class="code">
from sklearn.metrics import confusion_matrix, classification_report, plot_confusion_matrix
y_pred = clf.predict(X_test)
confusion_matrix(y_test,y_pred)
plot_confusion_matrix(clf,X_test,y_test)
print(classification_report(y_test,y_pred))
</pre>

KNN Метод ближайших соседей
<pre class="code">
from sklearn.neighbors import KNeighborsClassifier

knn = KNeighborsClassifier()

"confusion matrix" и отчёт "classification report"
from sklearn.metrics import confusion_matrix,classification_report
grid_pred = grid_model.predict(X_test)
confusion_matrix(y_test,grid_pred)
</pre>

Дерево решений Decision Tree Classificer
<pre class="code">
from sklearn.tree import DecisionTreeClassifier
dt = DecisionTreeClassifier(max_depth=6)
dt.fit(X_train, y_train)
</pre>

Посмотреть важность признаков для дерева решений
<pre class="code">
dt.feature_importances_ 

#или отобразить красиво на графике

imp_feats = pd.DataFrame(data=dt.feature_importances_, index=X.columns,columns=['Важность'])
imp_feats = imp_feats.sort_values('Важность')
imp_feats = imp_feats[imp_feats['Важность'] > 0]
plt.figure(figsize=(10,4),dpi=200)
sns.barplot(data=imp_feats,x=imp_feats.index,y='Важность')
plt.xticks(rotation=90);
</pre>

Случайный лес (Random Forest)
<pre class="code">
from sklearn.ensemble import RandomForestClassifier
rf = RandomForestClassifier(max_depth=6)
rf.fit(X_train, y_train)
preds = rf.predict(X_test)
</pre>

Расширяемые деревья (Boosted Trees) модель AdaBoost или Gradient Boosting
<pre class="code">
from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier
ada_model = AdaBoostClassifier(n_estimators=100)
gb_model = GradientBoostingClassifier()

ada_model.fit(X_train, y_train)
gb_model.fit(X_train, y_train)


NLP (Natural Language Processing)
from sklearn.pipeline import Pipeline
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import LinearSVC
from sklearn.naive_bayes import MultinomialNB
pipe = Pipeline([('tfidf', TfidfVectorizer()),('svc', LinearSVC()),])
pipe.fit(X_train, y_train) 
</pre>

<h2> Pipeline</h2>
<pre class="code">
from sklearn.pipeline import Pipeline

operations = [('scaler',scaler),('knn',knn)]
pipe = Pipeline(operations)
</pre>

<h2> DBSCAN</h2>

<pre class="code">
from sklearn.cluster import DBSCAN
number_of_outliers = []
for eps in np.linspace(0.001,3,50):
    dbscan = DBSCAN(eps=eps, min_samples=2*df_test.shape[1])
    dbscan.fit_predict(df_test)
    # Сохраняем количество точек выбросов
    number_of_outliers.append(np.sum(dbscan.labels_ == -1))
</pre>

Метод главных компонент (PCA - Principal Component Analysis)
<pre class="code">
from sklearn.decomposition import PCA
pca = PCA(n_components=2)
principal_components = pca.fit_transform(pixels_scaled)

np.sum(pca.explained_variance_ratio_) #сколько вариативности объясняется этими 2 главными компонентами
</pre>
</pre>
</body>
<script src="src/script.js"></script>
</html>
